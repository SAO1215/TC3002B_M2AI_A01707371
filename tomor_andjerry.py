# -*- coding: utf-8 -*-
"""tomOR_ANDjerry.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17d41d0LVENI3IzwPiAGfvhOXcm-h1JRX
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd "/content/drive/MyDrive/8 Semestre/Bloque 2/M2_IA/archive/tom_and_jerry"
!ls

import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from sklearn.metrics import confusion_matrix, classification_report

train_data_dir = 'tom_and_jerry_preprocessed/train'
valid_data_dir = 'tom_and_jerry_preprocessed/val'
test_data_dir = 'tom_and_jerry_preprocessed/test'

img_width, img_height = 150, 150
batch_size = 32

train_datagen = ImageDataGenerator(
    rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True)

valid_test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='categorical')

valid_generator = valid_test_datagen.flow_from_directory(
    valid_data_dir,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='categorical')

test_generator = valid_test_datagen.flow_from_directory(
    test_data_dir,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='categorical')

model = Sequential([
    Conv2D(4, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)),
    MaxPooling2D(2, 2),
    Conv2D(8, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Conv2D(16, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(4, activation='softmax')
])

model.summary()

model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.n // batch_size,
    epochs=15,
    validation_data=valid_generator,
    validation_steps=valid_generator.n // batch_size
)

test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.n // batch_size)
print(f"Test accuracy: {test_acc}")

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.style.use('ggplot')

plt.plot(epochs, acc, color = "#222831", label='Training accuracy')
plt.plot(epochs, val_acc, color = "#36D1DC", label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend()

plt.figure()

plt.plot(epochs, loss, color = "#222831", label='Training loss')
plt.plot(epochs, val_loss, color = "#36D1DC", label='Validation loss')
plt.title('Training and validation loss')
plt.legend()

plt.show()

predictions = model.predict(test_generator, steps=(test_generator.n // test_generator.batch_size) + 1)
predicted_classes = np.argmax(predictions, axis=-1)

true_classes = test_generator.classes

if len(predicted_classes) > len(true_classes):
    predicted_classes = predicted_classes[:len(true_classes)]

cm = confusion_matrix(true_classes, predicted_classes)
print(classification_report(true_classes, predicted_classes))

plt.figure(figsize=(10, 7))
sns.heatmap(cm, annot=True, fmt="d", cmap='Blues', xticklabels=list(test_generator.class_indices.keys()), yticklabels=list(test_generator.class_indices.keys()))
plt.title('Confusion Matrix')
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.show()

model.save("classif.keras")